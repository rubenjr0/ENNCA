{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/megarex/depthestimation?scriptVersionId=143618520\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Dependencies","metadata":{"papermill":{"duration":0.008506,"end_time":"2023-05-12T11:27:31.424312","exception":false,"start_time":"2023-05-12T11:27:31.415806","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install torch torchvision lightning torchmetrics\n!pip install -U --no-deps pytorch-optimizer","metadata":{"id":"jKx8b6f_MTCl","outputId":"3838a073-29ae-4ec8-b553-c63f767e240e","papermill":{"duration":16.146431,"end_time":"2023-05-12T11:27:47.577243","exception":false,"start_time":"2023-05-12T11:27:31.430812","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:56:09.82804Z","iopub.execute_input":"2023-09-19T23:56:09.828304Z","iopub.status.idle":"2023-09-19T23:56:31.166809Z","shell.execute_reply.started":"2023-09-19T23:56:09.828279Z","shell.execute_reply":"2023-09-19T23:56:31.165717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from os import cpu_count\nimport random\n\nimport torch\nfrom torch import nn, cat\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nimport torchvision.transforms as T\nfrom torchvision.transforms.functional import to_tensor, to_pil_image, resize\nfrom torchvision.utils import make_grid\nimport torchvision.models as models\n\nimport lightning.pytorch as pl\nfrom torchmetrics import StructuralSimilarityIndexMeasure\n\nfrom PIL import Image\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom pytorch_optimizer import Adan\n\nrandom.seed(42)\ntorch.manual_seed(42)","metadata":{"id":"jnbUOdMeL44W","papermill":{"duration":13.370843,"end_time":"2023-05-12T11:28:00.957559","exception":false,"start_time":"2023-05-12T11:27:47.586716","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:56:31.169183Z","iopub.execute_input":"2023-09-19T23:56:31.169648Z","iopub.status.idle":"2023-09-19T23:56:43.596678Z","shell.execute_reply.started":"2023-09-19T23:56:31.169609Z","shell.execute_reply":"2023-09-19T23:56:43.59573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"papermill":{"duration":0.009096,"end_time":"2023-05-12T11:28:00.976485","exception":false,"start_time":"2023-05-12T11:28:00.967389","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class NyuDataset(Dataset):\n    def __init__(self, root, csv, apply_transforms=True):\n        self.apply_transforms = apply_transforms\n        with open(f'{root}{csv}') as f:\n            self.samples = list(\n                map(\n                    lambda pair: list(\n                        map(\n                            lambda path: f'{root}{path}',\n                            pair.strip().split(','),\n                        )\n                    ),\n                    f.readlines(),\n                )\n            )\n\n    def __getitem__(self, index):\n        input_path, target_path = self.samples[index]\n        input_image = Image.open(input_path)\n        target_image = Image.open(target_path)\n        x_tensor = to_tensor(input_image)\n        y_tensor = to_tensor(target_image).float()\n        y_tensor = y_tensor / y_tensor.max()\n        # reduce the size to make the transforms less expensive\n        x_tensor = resize(x_tensor, size=[224, 224], antialias=True)\n        if self.apply_transforms:\n            # reduce the targets to stack them later\n            y_tensor = resize(y_tensor, size=[224, 224], antialias=True)\n            input_image = T.ColorJitter()(input_image)\n            t = T.Compose(\n                [\n                    T.RandomHorizontalFlip(),\n                    T.ColorJitter(),\n                    T.Normalize(0, 1)\n                ]\n            )\n            # stack and apply the same transformations to both\n            tensors = cat([x_tensor, y_tensor])\n            tensors = t(tensors)\n            x_tensor = tensors[0:3]\n            y_tensor = tensors[3:]\n        y_tensor = resize(y_tensor, size=[56, 56], antialias=True)\n        return x_tensor, y_tensor\n\n    def __len__(self):\n        return len(self.samples)","metadata":{"id":"XF2LyQBcMaAc","papermill":{"duration":0.02365,"end_time":"2023-05-12T11:28:01.009426","exception":false,"start_time":"2023-05-12T11:28:00.985776","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:56:43.598174Z","iopub.execute_input":"2023-09-19T23:56:43.598515Z","iopub.status.idle":"2023-09-19T23:56:43.610884Z","shell.execute_reply.started":"2023-09-19T23:56:43.59848Z","shell.execute_reply":"2023-09-19T23:56:43.6093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NyuDataModule(pl.LightningDataModule):\n    def __init__(self, root, csv_train, csv_test, batch_size: int = 32, apply_transforms=True):\n        super().__init__()\n        dataset = NyuDataset(root, csv_train, apply_transforms)\n        self.test = NyuDataset(root, csv_test, apply_transforms)\n        proportions = [.7, .3]\n        lengths = [int(p * len(dataset)) for p in proportions]\n        lengths[-1] = len(dataset) - sum(lengths[:-1])\n        self.train, self.val = random_split(dataset, lengths)\n        self.batch_size = batch_size\n        self.workers = cpu_count()\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train,\n            batch_size=self.batch_size,\n            num_workers=self.workers,\n            shuffle=True,\n            drop_last=True\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.val,\n            batch_size=self.batch_size,\n            num_workers=self.workers,\n            drop_last=True\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.test,\n            batch_size=self.batch_size,\n            num_workers=self.workers,\n        )\n","metadata":{"papermill":{"duration":0.021364,"end_time":"2023-05-12T11:28:01.039808","exception":false,"start_time":"2023-05-12T11:28:01.018444","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:56:43.613887Z","iopub.execute_input":"2023-09-19T23:56:43.614408Z","iopub.status.idle":"2023-09-19T23:56:43.626949Z","shell.execute_reply.started":"2023-09-19T23:56:43.6143Z","shell.execute_reply":"2023-09-19T23:56:43.625916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize(name, batch, model=None, n=4):\n    x, y = batch\n    n = min(n, len(x))\n    x = x[0:n]\n    y = y[0:n]\n    if model:\n        fig, ax = plt.subplots(nrows=3, ncols=n)\n    else:\n        fig, ax = plt.subplots(nrows=2, ncols=n)\n    fig.suptitle(name)\n    for i, axi in enumerate(ax.flat):\n        axi.axis(False)\n        image = x[i % n]\n        target = y[i % n].squeeze()\n        if i < n:\n            image = image.permute(1,2,0).cpu().numpy()\n            axi.imshow((image * 255).astype(np.uint8), cmap='gray');\n            if i % n == 0: axi.set_title('original image')\n        elif i < 2*n:\n            axi.imshow(target.cpu(), cmap='gray');\n            if i % n == 0: axi.set_title('real depth')\n        else:\n            image = image.unsqueeze(0)\n            estimated = model(image).detach().squeeze().squeeze()\n            axi.imshow(estimated.cpu(), cmap='gray');\n            if i % n == 0: axi.set_title('estimated depth')\n    fig.tight_layout()\n    return fig","metadata":{"papermill":{"duration":1.302018,"end_time":"2023-05-12T11:28:02.351201","exception":false,"start_time":"2023-05-12T11:28:01.049183","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:56:43.63041Z","iopub.execute_input":"2023-09-19T23:56:43.630686Z","iopub.status.idle":"2023-09-19T23:56:43.641584Z","shell.execute_reply.started":"2023-09-19T23:56:43.630663Z","shell.execute_reply":"2023-09-19T23:56:43.64066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vis_data = NyuDataModule('/kaggle/input/nyu-depth-v2/nyu_data/', 'data/nyu2_train.csv', 'data/nyu2_test.csv',\n                     batch_size=4, apply_transforms=True)\nvis_batch = next(iter(vis_data.test_dataloader()))\nvisualize('Data examples', vis_batch);","metadata":{"execution":{"iopub.status.busy":"2023-09-19T23:56:43.643088Z","iopub.execute_input":"2023-09-19T23:56:43.643414Z","iopub.status.idle":"2023-09-19T23:56:45.353456Z","shell.execute_reply.started":"2023-09-19T23:56:43.643383Z","shell.execute_reply":"2023-09-19T23:56:45.352497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"papermill":{"duration":0.011381,"end_time":"2023-05-12T11:28:02.374515","exception":false,"start_time":"2023-05-12T11:28:02.363134","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class EfficientNetWrapper(pl.LightningModule):\n    def __init__(self):\n        super(EfficientNetWrapper, self).__init__()\n        self.efficientnet = models.efficientnet_b0(\n            weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1\n        )\n        self.base_layers = nn.Sequential(\n            self.efficientnet.features[0],\n            self.efficientnet.features[1],\n            self.efficientnet.features[2],\n        )\n        self.layer1 = self.efficientnet.features[3]\n        self.layer2 = nn.Sequential(\n            self.efficientnet.features[4], self.efficientnet.features[5]\n        )\n        self.layer3 = self.efficientnet.features[6]\n        self.layer4 = self.efficientnet.features[7]\n        self.layer5 = self.efficientnet.features[8]\n\n    def get_features(self, x):\n        x = self.base_layers(x)\n        x1 = self.layer1(x)\n        x2 = self.layer2(x1)\n        x3 = self.layer3(x2)\n        x4 = self.layer4(x3)\n        x5 = self.layer5(x4)\n        return x1, x2, x3, x4, x5","metadata":{"papermill":{"duration":0.023262,"end_time":"2023-05-12T11:28:02.409429","exception":false,"start_time":"2023-05-12T11:28:02.386167","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:56:45.354731Z","iopub.execute_input":"2023-09-19T23:56:45.355936Z","iopub.status.idle":"2023-09-19T23:56:45.366618Z","shell.execute_reply.started":"2023-09-19T23:56:45.355876Z","shell.execute_reply":"2023-09-19T23:56:45.365732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BiFPN(nn.Module):\n    def __init__(self, fpn_sizes):\n        super(BiFPN, self).__init__()\n\n        (\n            P3_channels,\n            P4_channels,\n            P5_channels,\n            P6_channels,\n            P7_channels,\n        ) = fpn_sizes\n        self.W_bifpn = 64\n\n        # self.p6_td_conv  = nn.Conv2d(P6_channels, self.W_bifpn, kernel_size=3, stride=1, groups=self.W_bifpn, bias=True, padding=1)\n        self.p6_td_conv = nn.Conv2d(\n            P6_channels,\n            self.W_bifpn,\n            kernel_size=3,\n            stride=1,\n            bias=True,\n            padding=1,\n        )\n        self.p6_td_conv_2 = nn.Conv2d(\n            self.W_bifpn,\n            self.W_bifpn,\n            kernel_size=3,\n            stride=1,\n            groups=self.W_bifpn,\n            bias=True,\n            padding=1,\n        )\n        self.p6_td_act = nn.SELU() # RELU\n        self.p6_td_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n        self.p6_td_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p6_td_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n\n        self.p5_td_conv = nn.Conv2d(\n            P5_channels,\n            self.W_bifpn,\n            kernel_size=3,\n            stride=1,\n            bias=True,\n            padding=1,\n        )\n        self.p5_td_conv_2 = nn.Conv2d(\n            self.W_bifpn,\n            self.W_bifpn,\n            kernel_size=3,\n            stride=1,\n            groups=self.W_bifpn,\n            bias=True,\n            padding=1,\n        )\n        self.p5_td_act = nn.SELU() # RELU\n        self.p5_td_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n        self.p5_td_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p5_td_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n\n        self.p4_td_conv = nn.Conv2d(\n            P4_channels,\n            self.W_bifpn,\n            kernel_size=3,\n            stride=1,\n            bias=True,\n            padding=1,\n        )\n        self.p4_td_conv_2 = nn.Conv2d(\n            self.W_bifpn,\n            self.W_bifpn,\n            kernel_size=3,\n            stride=1,\n            groups=self.W_bifpn,\n            bias=True,\n            padding=1,\n        )\n        self.p4_td_act = nn.SELU() # RELU\n        self.p4_td_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n        self.p4_td_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p4_td_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p5_upsample = nn.Upsample(scale_factor=2, mode='nearest')\n\n        self.p3_out_conv = nn.Conv2d(\n            P3_channels,\n            self.W_bifpn,\n            kernel_size=3,\n            stride=1,\n            bias=True,\n            padding=1,\n        )\n        self.p3_out_conv_2 = nn.Conv2d(\n            self.W_bifpn,\n            self.W_bifpn,\n            kernel_size=3,\n            stride=1,\n            groups=self.W_bifpn,\n            bias=True,\n            padding=1,\n        )\n        self.p3_out_act = nn.SELU() # RELU\n        self.p3_out_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n        self.p3_out_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p3_out_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p4_upsample = nn.Upsample(scale_factor=2, mode='nearest')\n\n        # self.p4_out_conv = nn.Conv2d(P4_channels, self.W_bifpn, kernel_size=3, stride=1, bias=True, padding=1)\n        self.p4_out_conv = nn.Conv2d(\n            self.W_bifpn,\n            self.W_bifpn,\n            kernel_size=3,\n            stride=1,\n            groups=self.W_bifpn,\n            bias=True,\n            padding=1,\n        )\n        self.p4_out_act = nn.SELU() # RELU\n        self.p4_out_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n        self.p4_out_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p4_out_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p4_out_w3 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p3_downsample = nn.MaxPool2d(kernel_size=2)\n\n        # self.p5_out_conv = nn.Conv2d(P5_channels,self.W_bifpn, kernel_size=3, stride=1, bias=True, padding=1)\n        self.p5_out_conv = nn.Conv2d(\n            self.W_bifpn,\n            self.W_bifpn,\n            kernel_size=3,\n            stride=1,\n            groups=self.W_bifpn,\n            bias=True,\n            padding=1,\n        )\n        self.p5_out_act = nn.SELU() # RELU\n        self.p5_out_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n        self.p5_out_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p5_out_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p5_out_w3 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p4_downsample = nn.MaxPool2d(kernel_size=2)\n\n        # self.p6_out_conv = nn.Conv2d(P6_channels, self.W_bifpn, kernel_size=3, stride=1, bias=True, padding=1)\n        self.p6_out_conv = nn.Conv2d(\n            self.W_bifpn,\n            self.W_bifpn,\n            kernel_size=3,\n            stride=1,\n            groups=self.W_bifpn,\n            bias=True,\n            padding=1,\n        )\n        self.p6_out_act = nn.SELU() # RELU\n        self.p6_out_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n        self.p6_out_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p6_out_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p6_out_w3 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        # self.p4_downsample= nn.MaxPool2d(kernel_size=2)\n\n        self.p7_out_conv = nn.Conv2d(\n            P7_channels,\n            self.W_bifpn,\n            kernel_size=3,\n            stride=1,\n            bias=True,\n            padding=1,\n        )\n        self.p7_out_conv_2 = nn.Conv2d(\n            self.W_bifpn,\n            self.W_bifpn,\n            kernel_size=3,\n            stride=1,\n            groups=self.W_bifpn,\n            bias=True,\n            padding=1,\n        )\n        self.p7_out_act = nn.SELU() # RELU\n        self.p7_out_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n        self.p7_out_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n        self.p7_out_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n\n    def forward(self, inputs):\n        epsilon = 0.0001\n        P3, P4, P5, P6, P7 = inputs\n        # print (\"Input::\", P3.shape, P4.shape, P5.shape, P6.shape, P7.shape)\n        # P6_td = self.p6_td_conv((self.p6_td_w1 * P6 ) /\n        #                         (self.p6_td_w1 + epsilon))\n\n        P7_td = self.p7_out_conv(P7)\n\n        P6_td_inp = self.p6_td_conv(P6)\n        P6_td = self.p6_td_conv_2(\n            (self.p6_td_w1 * P6_td_inp + self.p6_td_w2 * P7_td) / self.p6_td_w1\n            + self.p6_td_w2\n            + epsilon\n        )\n        # P6_td = self.p6_td_conv_2(P6_td_inp)\n        P6_td = self.p6_td_act(P6_td)\n        P6_td = self.p6_td_conv_bn(P6_td)\n\n        P5_td_inp = self.p5_td_conv(P5)\n        # print (P5_td_inp.shape, P6_td.shape)\n        P5_td = self.p5_td_conv_2(\n            (self.p5_td_w1 * P5_td_inp + self.p5_td_w2 * P6_td)\n            / (self.p5_td_w1 + self.p5_td_w2 + epsilon)\n        )\n        P5_td = self.p5_td_act(P5_td)\n        P5_td = self.p5_td_conv_bn(P5_td)\n\n        # print (P4.shape, P5_td.shape)\n        P4_td_inp = self.p4_td_conv(P4)\n        P4_td = self.p4_td_conv_2(\n            (\n                self.p4_td_w1 * P4_td_inp\n                + self.p4_td_w2 * self.p5_upsample(P5_td)\n            )\n            / (self.p4_td_w1 + self.p4_td_w2 + epsilon)\n        )\n        P4_td = self.p4_td_act(P4_td)\n        P4_td = self.p4_td_conv_bn(P4_td)\n\n        P3_td = self.p3_out_conv(P3)\n        P3_out = self.p3_out_conv_2(\n            (self.p3_out_w1 * P3_td + self.p3_out_w2 * self.p4_upsample(P4_td))\n            / (self.p3_out_w1 + self.p3_out_w2 + epsilon)\n        )\n        P3_out = self.p3_out_act(P3_out)\n        P3_out = self.p3_out_conv_bn(P3_out)\n\n        # print (P4_td.shape, P3_out.shape)\n\n        P4_out = self.p4_out_conv(\n            (\n                self.p4_out_w1 * P4_td_inp\n                + self.p4_out_w2 * P4_td\n                + self.p4_out_w3 * self.p3_downsample(P3_out)\n            )\n            / (self.p4_out_w1 + self.p4_out_w2 + self.p4_out_w3 + epsilon)\n        )\n        P4_out = self.p4_out_act(P4_out)\n        P4_out = self.p4_out_conv_bn(P4_out)\n\n        P5_out = self.p5_out_conv(\n            (\n                self.p5_out_w1 * P5_td_inp\n                + self.p5_out_w2 * P5_td\n                + self.p5_out_w3 * self.p4_downsample(P4_out)\n            )\n            / (self.p5_out_w2 + self.p5_out_w3 + epsilon)\n        )\n        P5_out = self.p5_out_act(P5_out)\n        P5_out = self.p5_out_conv_bn(P5_out)\n\n        P6_out = self.p6_out_conv(\n            (\n                self.p6_out_w1 * P6_td_inp\n                + self.p6_out_w2 * P6_td\n                + self.p6_out_w3 * (P5_out)\n            )\n            / (self.p6_out_w1 + self.p6_out_w2 + self.p6_out_w3 + epsilon)\n        )\n        P6_out = self.p6_out_act(P6_out)\n        P6_out = self.p6_out_conv_bn(P6_out)\n\n        P7_out = self.p7_out_conv_2(\n            (self.p7_out_w1 * P7_td + self.p7_out_w2 * P6_out)\n            / (self.p7_out_w1 + self.p7_out_w2 + epsilon)\n        )\n        P7_out = self.p7_out_act(P7_out)\n        P7_out = self.p7_out_conv_bn(P7_out)\n\n        return [P3_out, P4_out, P5_out, P6_out, P7_out]","metadata":{"papermill":{"duration":0.051862,"end_time":"2023-05-12T11:28:02.472686","exception":false,"start_time":"2023-05-12T11:28:02.420824","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:56:45.368268Z","iopub.execute_input":"2023-09-19T23:56:45.369218Z","iopub.status.idle":"2023-09-19T23:56:45.407748Z","shell.execute_reply.started":"2023-09-19T23:56:45.369185Z","shell.execute_reply":"2023-09-19T23:56:45.406821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bifpn = BiFPN([40, 112, 192, 320, 1280])\n        self.upsample1 = nn.PixelShuffle(2)\n        self.upsample2 = nn.PixelShuffle(4)\n        self.bn = nn.BatchNorm2d(20)\n        self.act = nn.SELU()\n\n    def forward(self, x):\n        x1, x2, _, _, _ = self.bifpn(x)\n        x1 = self.upsample1(x1)\n        x2 = self.upsample2(x2)\n        x = torch.cat([x1, x2], 1)\n        x = self.bn(x)\n        x = self.act(x)\n        return x","metadata":{"papermill":{"duration":0.021509,"end_time":"2023-05-12T11:28:02.50735","exception":false,"start_time":"2023-05-12T11:28:02.485841","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:56:45.409216Z","iopub.execute_input":"2023-09-19T23:56:45.409589Z","iopub.status.idle":"2023-09-19T23:56:45.419843Z","shell.execute_reply.started":"2023-09-19T23:56:45.409558Z","shell.execute_reply":"2023-09-19T23:56:45.418824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_dims, out_dims, kernel_size=3, extras=True):\n        super().__init__()\n        self.depth_conv = nn.Conv2d(in_dims, in_dims, kernel_size=kernel_size, padding=kernel_size//2, groups=in_dims)\n        self.point_conv = nn.Conv2d(in_dims, out_dims, kernel_size=1)\n        self.bn = nn.BatchNorm2d(out_dims) if extras else None\n        self.act = nn.SELU() if extras else None\n\n    def forward(self, x):\n        x = self.depth_conv(x)\n        x = self.point_conv(x)\n        if self.bn:\n            x = self.bn(x)\n            x = self.act(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-09-19T23:56:45.425351Z","iopub.execute_input":"2023-09-19T23:56:45.425621Z","iopub.status.idle":"2023-09-19T23:56:45.435355Z","shell.execute_reply.started":"2023-09-19T23:56:45.425587Z","shell.execute_reply":"2023-09-19T23:56:45.434468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class InceptionCore(nn.Module):\n    def __init__(self, in_dims, base=16):\n        super().__init__()\n        self.branch_1_1 = nn.Conv2d(in_dims, base, 1)\n        self.branch_1_3 = nn.Conv2d(base, base*2, 3, padding=1)\n        self.branch_1_13 = nn.Conv2d(base*2, base*3, (1,3), padding=(0,1))\n        self.branch_1_31 = nn.Conv2d(base*2, base*3, (3,1), padding=(1,0))\n\n        self.branch_2_1 = nn.Conv2d(in_dims, base, 1)\n        self.branch_2_13 = nn.Conv2d(base, base*2, (1,3), padding=(0,1))\n        self.branch_2_31 = nn.Conv2d(base, base*2, (3,1), padding=(1,0))\n        \n        self.branch_3_1 = nn.Conv2d(in_dims, base, 1)\n        \n        self.downsample = nn.Conv2d(in_dims, base*11, 1, bias=False)\n\n    def forward(self, x):\n        branch_1 = self.branch_1_1(x)\n        branch_1 = self.branch_1_3(branch_1)\n        branch_1_1 = self.branch_1_13(branch_1)\n        branch_1_2 = self.branch_1_31(branch_1)\n\n        branch_2 = self.branch_2_1(x)\n        branch_2_1 = self.branch_2_13(branch_2)\n        branch_2_2 = self.branch_2_31(branch_2)\n\n        branch_3 = self.branch_3_1(x)\n\n        res = self.downsample(x)\n\n        x = torch.cat([branch_1_1, branch_1_2, branch_2_1, branch_2_2, branch_3], dim=1)\n        x += res\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-09-19T23:56:45.436534Z","iopub.execute_input":"2023-09-19T23:56:45.438116Z","iopub.status.idle":"2023-09-19T23:56:45.449148Z","shell.execute_reply.started":"2023-09-19T23:56:45.438084Z","shell.execute_reply":"2023-09-19T23:56:45.448398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DepthNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = EfficientNetWrapper()\n        # self.encoder.freeze()\n        self.d1 = Decoder()\n        self.d2 = Decoder()\n        self.d3 = Decoder()\n        self.downsample = nn.Sequential(\n            nn.Conv2d(3, 60, 1, bias=False),\n            nn.MaxPool2d(4)\n        )\n        self.head = nn.Sequential(\n            InceptionCore(60),\n            ConvBlock(176, 40),\n            ConvBlock(40, 1, extras=False),\n        )\n        self.act = nn.ReLU6()\n\n    def forward(self, x):\n        res1 = self.downsample(x)\n        x = self.encoder.get_features(x)\n        x1 = self.d1(x)\n        x2 = self.d2(x)\n        x3 = self.d3(x)\n        x = cat([x1, x2, x3], 1)\n        x += res1\n        x = self.head(x)\n        x = self.act(x)\n        return x","metadata":{"papermill":{"duration":0.023321,"end_time":"2023-05-12T11:28:02.576763","exception":false,"start_time":"2023-05-12T11:28:02.553442","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:56:45.451531Z","iopub.execute_input":"2023-09-19T23:56:45.45209Z","iopub.status.idle":"2023-09-19T23:56:45.461167Z","shell.execute_reply.started":"2023-09-19T23:56:45.452052Z","shell.execute_reply":"2023-09-19T23:56:45.460475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Module definition","metadata":{"papermill":{"duration":0.011261,"end_time":"2023-05-12T11:28:02.599524","exception":false,"start_time":"2023-05-12T11:28:02.588263","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class LitDepth(pl.LightningModule):\n    def __init__(self, learning_rate=2e-3, weight_decay=1e-4):\n        super(LitDepth, self).__init__()\n        self.save_hyperparameters()\n        self.net = DepthNet()\n        self.loss = torch.nn.MSELoss()\n        self.accuracy = StructuralSimilarityIndexMeasure(data_range=1.0)\n\n    def forward(self, x):\n        x = self.net(x)\n        return x\n\n    def _do_stuff(self, batch, name):\n        x, y = batch\n        estimated = self(x)\n        acc = self.accuracy(estimated, y)\n        self.log(f'{name}_acc', acc)\n        loss = self.loss(estimated, y)\n        self.log(f'{name}_loss', loss)\n        return loss\n\n    def training_step(self, batch, _batch_idx):\n        return self._do_stuff(batch, 'train')\n\n    def validation_step(self, batch, _batch_idx):\n        loss = self._do_stuff(batch, 'validation')\n        self.log('hp_metric', loss)\n        return loss\n\n    def test_step(self, batch, _batch_idx):\n        return self._do_stuff(batch, 'test')\n\n    def configure_optimizers(self):\n        lr = self.hparams.learning_rate\n        wd = self.hparams.weight_decay\n        optimizer = Adan(self.parameters(), lr=lr, weight_decay=wd)\n        return optimizer\n","metadata":{"id":"wgzESH1IM1k9","papermill":{"duration":0.024257,"end_time":"2023-05-12T11:28:02.635188","exception":false,"start_time":"2023-05-12T11:28:02.610931","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:56:45.46244Z","iopub.execute_input":"2023-09-19T23:56:45.463091Z","iopub.status.idle":"2023-09-19T23:56:45.473739Z","shell.execute_reply.started":"2023-09-19T23:56:45.463058Z","shell.execute_reply":"2023-09-19T23:56:45.473061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"papermill":{"duration":0.011172,"end_time":"2023-05-12T11:28:02.657762","exception":false,"start_time":"2023-05-12T11:28:02.64659","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Image callback","metadata":{"papermill":{"duration":0.011496,"end_time":"2023-05-12T11:28:02.680824","exception":false,"start_time":"2023-05-12T11:28:02.669328","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class ImageSampler(pl.callbacks.Callback):\n    def __init__(\n        self,\n        num_samples: int = 3,\n        nrow: int = 8,\n        padding: int = 2,\n        normalize: bool = True,\n        norm_range = None,\n        scale_each: bool = False,\n        pad_value: int = 0,\n    ) -> None:\n        \"\"\"\n        Args:\n            num_samples: Number of images displayed in the grid. Default: ``3``.\n            nrow: Number of images displayed in each row of the grid.\n                The final grid size is ``(B / nrow, nrow)``. Default: ``8``.\n            padding: Amount of padding. Default: ``2``.\n            normalize: If ``True``, shift the image to the range (0, 1),\n                by the min and max values specified by :attr:`range`. Default: ``False``.\n            norm_range: Tuple (min, max) where min and max are numbers,\n                then these numbers are used to normalize the image. By default, min and max\n                are computed from the tensor.\n            scale_each: If ``True``, scale each image in the batch of\n                images separately rather than the (min, max) over all images. Default: ``False``.\n            pad_value: Value for the padded pixels. Default: ``0``.\n        \"\"\"\n        super().__init__()\n        self.num_samples = num_samples\n        self.nrow = nrow\n        self.padding = padding\n        self.normalize = normalize\n        self.norm_range = norm_range\n        self.scale_each = scale_each\n        self.pad_value = pad_value\n        \n    def to_grid(self, images):\n        return make_grid(\n            tensor=images,\n            nrow=self.nrow,\n            padding=self.padding,\n            normalize=self.normalize,\n            range=self.norm_range,\n            scale_each=self.scale_each,\n            pad_value=self.pad_value,\n        )\n\n    def on_fit_start(self, trainer, pl_module):\n        logger = pl_module.logger.experiment\n        images, ground_truth = next(iter(DataLoader(trainer.datamodule.val, batch_size=self.num_samples)))\n        # image_grid = self.to_grid(images)\n        # target_grid = self.to_grid(targets)\n        logger.add_images(\"original images\", images)\n        logger.add_images(\"real depth\", ground_truth)\n\n    def on_validation_epoch_end(self, trainer, pl_module) -> None:\n        logger = pl_module.logger.experiment\n        images, targets = next(iter(DataLoader(trainer.datamodule.val, batch_size=self.num_samples)))\n        # generate images\n        estimated = pl_module(images.to(pl_module.device)).detach()\n        # estimated_grid = to_pil_image(self.to_grid(estimated))\n        logger.add_images(\"estimated depth\", estimated, trainer.current_epoch)\n        \n    def on_test_epoch_end(self, trainer, pl_module) -> None:\n        logger = pl_module.logger.experiment\n        images, targets = next(iter(DataLoader(trainer.datamodule.test, batch_size=self.num_samples)))\n        # generate images\n        estimated = pl_module(images.to(pl_module.device)).detach()\n        # estimated_grid = to_pil_image(self.to_grid(estimated))\n        logger.add_images(\"test images\", images)\n        logger.add_images(\"test estimation\", estimated)","metadata":{"papermill":{"duration":0.027187,"end_time":"2023-05-12T11:28:02.719265","exception":false,"start_time":"2023-05-12T11:28:02.692078","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:56:45.475093Z","iopub.execute_input":"2023-09-19T23:56:45.47573Z","iopub.status.idle":"2023-09-19T23:56:45.490159Z","shell.execute_reply.started":"2023-09-19T23:56:45.475695Z","shell.execute_reply":"2023-09-19T23:56:45.489238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Experiment definitions","metadata":{"papermill":{"duration":0.011425,"end_time":"2023-05-12T11:28:02.742288","exception":false,"start_time":"2023-05-12T11:28:02.730863","status":"completed"},"tags":[]}},{"cell_type":"code","source":"experiments = [{\n    'name': 'low_lr_with_augs',\n    'lr': 2e-4,\n    'augs': True\n    },\n    {\n    'name': 'mid_lr_with_augs',\n    'lr': 2e-3,\n    'augs': True\n    },\n    {\n    'name': 'high_lr_with_augs',\n    'lr': 8e-3,\n    'augs': True\n    },\n    {\n    'name': 'without_augs',\n    'lr': 2e-3,\n    'augs': False\n}]","metadata":{"papermill":{"duration":0.019572,"end_time":"2023-05-12T11:28:02.773914","exception":false,"start_time":"2023-05-12T11:28:02.754342","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:56:45.491685Z","iopub.execute_input":"2023-09-19T23:56:45.492543Z","iopub.status.idle":"2023-09-19T23:56:45.501869Z","shell.execute_reply.started":"2023-09-19T23:56:45.492506Z","shell.execute_reply":"2023-09-19T23:56:45.50094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trainer Definition","metadata":{"papermill":{"duration":0.01155,"end_time":"2023-05-12T11:28:02.796918","exception":false,"start_time":"2023-05-12T11:28:02.785368","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def run_experiment(name, lr, augs):\n#     early_stop_callback = pl.callbacks.EarlyStopping(\n#         monitor='validation_loss',\n#         min_delta=1e-3,\n#         patience=8,\n#         mode='min',\n#         verbose=True\n#     )\n\n    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n        dirpath='/kaggle/working/models/',\n        filename=f'best_model_{name}',\n        save_top_k=1,\n        monitor='validation_loss',\n        mode='min',\n    )\n    \n    tb_logger = pl.loggers.TensorBoardLogger(\n        save_dir='/kaggle/working/',\n        name='tb_logs',\n        version=name\n    )\n\n    data = NyuDataModule(\n        root='/kaggle/input/nyu-depth-v2/nyu_data/',\n        csv_train='data/nyu2_train.csv',\n        csv_test='data/nyu2_test.csv',\n        batch_size=32,\n        apply_transforms=augs\n    )\n\n    model = LitDepth(learning_rate = lr)\n\n    trainer = pl.Trainer(\n        default_root_dir='/kaggle/working/',\n        callbacks=[\n            # early_stop_callback,\n            checkpoint_callback,\n            ImageSampler(),\n            pl.callbacks.LearningRateMonitor(),\n            pl.callbacks.ModelSummary(),\n        ],\n        max_epochs=30,\n        precision=16,\n        logger=tb_logger,\n        gradient_clip_val=0.5,\n        # limit_train_batches=8,\n        # limit_test_batches=8,\n        # limit_val_batches=8,\n        # detect_anomaly=True,\n        # fast_dev_run=True,\n        # profiler=\"simple\"\n    )\n\n    print('Starting training...')\n    trainer.fit(model, datamodule=data)\n\n    print('Starting testing...')\n    trainer.test(model, datamodule=data)\n    \n    model.eval()\n    model.freeze()\n    visualize(f'{name} estimation', vis_batch, model);","metadata":{"id":"lKEQ6grTZaY5","outputId":"3ca511d2-9d7a-4934-f0c8-6225f2193d0b","papermill":{"duration":0.026933,"end_time":"2023-05-12T11:28:02.835365","exception":false,"start_time":"2023-05-12T11:28:02.808432","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:56:45.503467Z","iopub.execute_input":"2023-09-19T23:56:45.504202Z","iopub.status.idle":"2023-09-19T23:56:45.514369Z","shell.execute_reply.started":"2023-09-19T23:56:45.504169Z","shell.execute_reply":"2023-09-19T23:56:45.513393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Runs","metadata":{"papermill":{"duration":0.011147,"end_time":"2023-05-12T11:28:02.857928","exception":false,"start_time":"2023-05-12T11:28:02.846781","status":"completed"},"tags":[]}},{"cell_type":"code","source":"run_experiment(**experiments[-1])","metadata":{"execution":{"iopub.status.busy":"2023-09-19T23:56:45.515815Z","iopub.execute_input":"2023-09-19T23:56:45.516431Z","iopub.status.idle":"2023-09-19T23:57:05.11875Z","shell.execute_reply.started":"2023-09-19T23:56:45.516399Z","shell.execute_reply":"2023-09-19T23:57:05.117802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for (i, exp) in enumerate(experiments):\n#    print(f'Running experiment {i+1}/{len(experiments)}:', exp)\n#    run_experiment(**exp)","metadata":{"papermill":{"duration":21128.613103,"end_time":"2023-05-12T17:20:11.482662","exception":false,"start_time":"2023-05-12T11:28:02.869559","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T23:57:05.120169Z","iopub.execute_input":"2023-09-19T23:57:05.122172Z","iopub.status.idle":"2023-09-19T23:57:05.126976Z","shell.execute_reply.started":"2023-09-19T23:57:05.122136Z","shell.execute_reply":"2023-09-19T23:57:05.12513Z"},"trusted":true},"execution_count":null,"outputs":[]}]}